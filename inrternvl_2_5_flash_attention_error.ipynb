{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gg5YT1JIdlwG",
        "outputId": "dbd9d169-c4ef-4330-bfd3-a89aa0a7cff5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'InternVL' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/OpenGVLab/InternVL.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Mrkl0yijeBmb"
      },
      "outputs": [],
      "source": [
        "# !huggingface-cli download --resume-download --local-dir-use-symlinks False OpenGVLab/InternVL2_5-1B-MPO --local-dir InternVL2_5-1B-MPO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M96w_EtVfrrc"
      },
      "source": [
        "# Dataset Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "559VzMmUgKXf",
        "outputId": "9ccd2a04-4356-4b1c-ad52-eb20952f3517"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9e9zJ_OKeMGK"
      },
      "outputs": [],
      "source": [
        "# hugging face dataset download\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"your_dataset\", token=\"input_token\", split='train[:100]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Wz8e-siyfqgy",
        "outputId": "68cfd246-9f4b-4e93-e2a4-18e16fe3188e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image', 'question', 'answer'],\n",
              "    num_rows: 100\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rmmgI4GmhQN4"
      },
      "outputs": [],
      "source": [
        "# dataset[\"image\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aQER8wASixKV",
        "outputId": "3e44ae5d-a3ab-49e0-e75f-a4e01d92f974"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All images have been saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# Step 1: Create dataset folder and image folder\n",
        "dataset_folder = \"dataset_folder\"\n",
        "image_folder = os.path.join(dataset_folder, \"images\")\n",
        "\n",
        "os.makedirs(image_folder, exist_ok=True)\n",
        "\n",
        "# Step 2: Save images to the 'images' folder\n",
        "for idx, sample in enumerate(dataset):\n",
        "    # Assuming dataset has an 'image' column with PIL Image or URL\n",
        "    if isinstance(sample['image'], Image.Image):\n",
        "        image = sample['image']\n",
        "    else:\n",
        "        # If it's a URL, download the image\n",
        "        response = requests.get(sample['image']['url'])\n",
        "        image = Image.open(BytesIO(response.content))\n",
        "\n",
        "    # Save the image\n",
        "    image_path = os.path.join(image_folder, f\"image_{idx}.jpg\")\n",
        "    image.save(image_path)\n",
        "    # print(f\"Saved: {image_path}\")\n",
        "\n",
        "print(\"All images have been saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0ihDydQFjm_s"
      },
      "outputs": [],
      "source": [
        "final_dataset_json = []\n",
        "relative_image_path = \"/content/dataset_folder/images\"\n",
        "for idx, sample in enumerate(dataset):\n",
        "    temp_json_dataset = {}\n",
        "\n",
        "    x, y = dataset[\"image\"][idx].size\n",
        "    # Assuming dataset has an 'image' column with PIL Image or URL\n",
        "    # print(sample[\"question\"], sample[\"answer\"])\n",
        "\n",
        "\n",
        "    temp_json_dataset[\"id\"] = idx\n",
        "    temp_json_dataset[\"image\"] = f\"{relative_image_path}/image_{idx}.jpg\"\n",
        "    temp_json_dataset[\"width\"] = x\n",
        "    temp_json_dataset[\"height\"] = y\n",
        "    temp_json_dataset[\"conversations\"] = [\n",
        "      {\n",
        "        \"from\": \"human\",\n",
        "        \"value\": f\"<image>\\n{sample['question']}\"\n",
        "      },\n",
        "      {\n",
        "        \"from\": \"gpt\",\n",
        "        \"value\": f\"{sample['answer']}\"\n",
        "      }\n",
        "    ]\n",
        "    final_dataset_json.append(temp_json_dataset)\n",
        "\n",
        "    # if idx == 2:\n",
        "    #   break\n",
        "\n",
        "    # break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOgsou66L4l0"
      },
      "source": [
        "In this format json file required\n",
        "```\n",
        "{\n",
        "  \"id\": 0,\n",
        "  \"image\": \"images/00000000.jpg\",\n",
        "  \"width\": 897,\n",
        "  \"height\": 1152,\n",
        "  \"conversations\": [\n",
        "    {\n",
        "      \"from\": \"human\",\n",
        "      \"value\": \"<image>\\nCan you extract any readable text from the image?\"\n",
        "    },\n",
        "    {\n",
        "      \"from\": \"gpt\",\n",
        "      \"value\": \"Dares Wins Vol. 5 Tommy's Heroes Vol. 6: For Tomorrow Vol. 7: Closing Time miniseries. Clark Kent is being interviewed about Superman's connection to notorious killer Tommy Monaghan. Taking the conversation...\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_hLtqgjYkMsJ"
      },
      "outputs": [],
      "source": [
        "# final_dataset_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4AY6ogzyMP1p"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('data.jsonl', 'w') as jsonl_file:\n",
        "    for item in final_dataset_json:\n",
        "        # Convert the dictionary to a JSON string\n",
        "        json_line = json.dumps(item)\n",
        "\n",
        "        # Write the JSON string followed by a newline\n",
        "        jsonl_file.write(json_line + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SM1RjoKyNENW"
      },
      "outputs": [],
      "source": [
        "# creating meta_data_file for data information\n",
        "import json\n",
        "\n",
        "meta_data = {\n",
        "    \"data\": {\n",
        "        \"root\": \"/content/dataset_folder/images\",\n",
        "        \"annotation\": \"/content/data.jsonl\",\n",
        "        \"data_augment\": False,\n",
        "        \"repeat_time\": 1,\n",
        "        \"length\": len(dataset)\n",
        "    }\n",
        "}\n",
        "with open(\"/content/InternVL/internvl_chat/shell/data/train_metadata.jsonl\", \"w\") as f:\n",
        "    json.dump(meta_data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aOw8hyvFgaYM"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Get the current script's directory or set a custom path\n",
        "# current_path = os.path.abspath(\"/content/InternVL\")\n",
        "\n",
        "# # Add the directory to sys.path\n",
        "# if current_path not in sys.path:\n",
        "#     sys.path.append(current_path)\n",
        "\n",
        "sys.path.append(\"/content/InternVL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RQDmQ-9TioZC"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/InternVL/internvl_chat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gooBqNStir0v",
        "outputId": "3abd3821-5fc3-4f9f-8d7b-7550d0fb41e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/InternVL/internvl_chat\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "E18tZDx8y6AI"
      },
      "outputs": [],
      "source": [
        "# !pip install flash-attn==2.0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "p0zssUBo4nu0",
        "outputId": "5d911cb9-3bf6-45b3-f67d-4639d0c9e13f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate<1 in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 1)) (0.34.2)\n",
            "Collecting bitsandbytes==0.42.0 (from -r /content/InternVL/requirements/internvl_chat.txt (line 2))\n",
            "  Using cached bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: decord in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 3)) (0.6.0)\n",
            "Requirement already satisfied: deepspeed>=0.13.5 in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 4)) (0.16.4)\n",
            "Requirement already satisfied: einops==0.6.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 5)) (0.6.1)\n",
            "Requirement already satisfied: einops-exts==0.0.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 6)) (0.0.4)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 7)) (0.28.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 8)) (2.37.0)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 9)) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 10)) (4.11.0.86)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 11)) (3.10.15)\n",
            "Requirement already satisfied: peft==0.10.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 12)) (0.10.0)\n",
            "Requirement already satisfied: pycocoevalcap in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 13)) (1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 14)) (6.0.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 15)) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 16)) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece==0.1.99 in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 17)) (0.1.99)\n",
            "Requirement already satisfied: shortuuid in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 18)) (1.0.13)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 19)) (2.6.2.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 20)) (2.5.0)\n",
            "Requirement already satisfied: timm==0.9.12 in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 21)) (0.9.12)\n",
            "Requirement already satisfied: tokenizers==0.15.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 22)) (0.15.1)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 23)) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.15 in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 24)) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 25)) (4.67.1)\n",
            "Requirement already satisfied: transformers==4.37.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 26)) (4.37.2)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.11/dist-packages (from -r /content/InternVL/requirements/internvl_chat.txt (line 27)) (0.1.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0->-r /content/InternVL/requirements/internvl_chat.txt (line 12)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0->-r /content/InternVL/requirements/internvl_chat.txt (line 12)) (5.9.5)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0->-r /content/InternVL/requirements/internvl_chat.txt (line 12)) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2->-r /content/InternVL/requirements/internvl_chat.txt (line 26)) (3.17.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2->-r /content/InternVL/requirements/internvl_chat.txt (line 26)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2->-r /content/InternVL/requirements/internvl_chat.txt (line 26)) (2.32.3)\n",
            "Requirement already satisfied: hjson in /usr/local/lib/python3.11/dist-packages (from deepspeed>=0.13.5->-r /content/InternVL/requirements/internvl_chat.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from deepspeed>=0.13.5->-r /content/InternVL/requirements/internvl_chat.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from deepspeed>=0.13.5->-r /content/InternVL/requirements/internvl_chat.txt (line 4)) (1.11.1.3)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from deepspeed>=0.13.5->-r /content/InternVL/requirements/internvl_chat.txt (line 4)) (9.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from deepspeed>=0.13.5->-r /content/InternVL/requirements/internvl_chat.txt (line 4)) (2.10.6)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.11/dist-packages (from deepspeed>=0.13.5->-r /content/InternVL/requirements/internvl_chat.txt (line 4)) (12.570.86)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->-r /content/InternVL/requirements/internvl_chat.txt (line 7)) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->-r /content/InternVL/requirements/internvl_chat.txt (line 7)) (4.12.2)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio->-r /content/InternVL/requirements/internvl_chat.txt (line 8)) (11.1.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from pycocoevalcap->-r /content/InternVL/requirements/internvl_chat.txt (line 13)) (2.0.8)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.2->-r /content/InternVL/requirements/internvl_chat.txt (line 15)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.2->-r /content/InternVL/requirements/internvl_chat.txt (line 15)) (3.5.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX->-r /content/InternVL/requirements/internvl_chat.txt (line 19)) (4.25.6)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2->-r /content/InternVL/requirements/internvl_chat.txt (line 23)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->-r /content/InternVL/requirements/internvl_chat.txt (line 23)) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->-r /content/InternVL/requirements/internvl_chat.txt (line 23)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->-r /content/InternVL/requirements/internvl_chat.txt (line 23)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->-r /content/InternVL/requirements/internvl_chat.txt (line 23)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2->-r /content/InternVL/requirements/internvl_chat.txt (line 23)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2->-r /content/InternVL/requirements/internvl_chat.txt (line 23)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2->-r /content/InternVL/requirements/internvl_chat.txt (line 23)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2->-r /content/InternVL/requirements/internvl_chat.txt (line 23)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2->-r /content/InternVL/requirements/internvl_chat.txt (line 23)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2->-r /content/InternVL/requirements/internvl_chat.txt (line 23)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2->-r /content/InternVL/requirements/internvl_chat.txt (line 23)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->-r /content/InternVL/requirements/internvl_chat.txt (line 23)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->-r /content/InternVL/requirements/internvl_chat.txt (line 23)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->-r /content/InternVL/requirements/internvl_chat.txt (line 23)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2->-r /content/InternVL/requirements/internvl_chat.txt (line 23)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2->-r /content/InternVL/requirements/internvl_chat.txt (line 23)) (1.3.0)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools>=2.0.2->pycocoevalcap->-r /content/InternVL/requirements/internvl_chat.txt (line 13)) (3.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed>=0.13.5->-r /content/InternVL/requirements/internvl_chat.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed>=0.13.5->-r /content/InternVL/requirements/internvl_chat.txt (line 4)) (2.27.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2->-r /content/InternVL/requirements/internvl_chat.txt (line 23)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2->-r /content/InternVL/requirements/internvl_chat.txt (line 26)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2->-r /content/InternVL/requirements/internvl_chat.txt (line 26)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2->-r /content/InternVL/requirements/internvl_chat.txt (line 26)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2->-r /content/InternVL/requirements/internvl_chat.txt (line 26)) (2025.1.31)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap->-r /content/InternVL/requirements/internvl_chat.txt (line 13)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap->-r /content/InternVL/requirements/internvl_chat.txt (line 13)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap->-r /content/InternVL/requirements/internvl_chat.txt (line 13)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap->-r /content/InternVL/requirements/internvl_chat.txt (line 13)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap->-r /content/InternVL/requirements/internvl_chat.txt (line 13)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap->-r /content/InternVL/requirements/internvl_chat.txt (line 13)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap->-r /content/InternVL/requirements/internvl_chat.txt (line 13)) (1.17.0)\n",
            "Using cached bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "Installing collected packages: bitsandbytes\n",
            "  Attempting uninstall: bitsandbytes\n",
            "    Found existing installation: bitsandbytes 0.45.2\n",
            "    Uninstalling bitsandbytes-0.45.2:\n",
            "      Successfully uninstalled bitsandbytes-0.45.2\n",
            "Successfully installed bitsandbytes-0.42.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/InternVL/requirements/internvl_chat.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QNnkRKXtg5nO"
      },
      "outputs": [],
      "source": [
        "# !pip install deepspeed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8Mpw7H9J5ZVC",
        "outputId": "cf4a8428-9264-4ad3-830b-0f523d4d97bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Feb 21 15:39:08 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "BBmvbpBXaQhv"
      },
      "outputs": [],
      "source": [
        "# !GPUS=1 PER_DEVICE_BATCH_SIZE=1 sh /content/InternVL/internvl_chat/shell/internvl2.5_mpo/preference_optimization/internvl2_5_1b_qwen2_5_0_5b_dynamic_res_mpo.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "n-JTPwk4Gv8W"
      },
      "outputs": [],
      "source": [
        "# !pip install flash_attn exllamav2 -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ia3Ul6H6HLOh",
        "outputId": "bb85a924-bdbc-44de-fe63-bab9ddf505d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.42.0)\n",
            "Collecting bitsandbytes\n",
            "  Using cached bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Using cached bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n",
            "Installing collected packages: bitsandbytes\n",
            "  Attempting uninstall: bitsandbytes\n",
            "    Found existing installation: bitsandbytes 0.42.0\n",
            "    Uninstalling bitsandbytes-0.42.0:\n",
            "      Successfully uninstalled bitsandbytes-0.42.0\n",
            "Successfully installed bitsandbytes-0.45.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4phew-m0HIV4"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "w2m1dysJWPcr",
        "outputId": "35e1b112-437f-4347-9088-ecda7490a96c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: flash_attn 2.7.4.post1\n",
            "Uninstalling flash_attn-2.7.4.post1:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.11/dist-packages/flash_attn-2.7.4.post1.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/flash_attn/*\n",
            "    /usr/local/lib/python3.11/dist-packages/flash_attn_2_cuda.cpython-311-x86_64-linux-gnu.so\n",
            "    /usr/local/lib/python3.11/dist-packages/hopper/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled flash_attn-2.7.4.post1\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m155.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.5.1+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp311-cp311-linux_x86_64.whl size=187815463 sha256=d944fc7d2f962bce83fc4708c2fc0c21eaf8255962a0b350ae919362a51b7ef2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-o9gspuw3/wheels/3d/88/d8/284b89f56af7d5bf366b10d6b8e251ac8a7c7bf3f04203fb4f\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.7.4.post1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall flash-attn\n",
        "!pip install flash-attn --no-build-isolation --no-cache-dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nIqcJhuiV7TN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
        "path = \"OpenGVLab/InternVL2_5-1B\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FH6R9EzWiohz",
        "outputId": "27c0fd3b-3303-4ca3-f2e2-afc71a253e12"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for OpenGVLab/InternVL2_5-1B contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/OpenGVLab/InternVL2_5-1B.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        }
      ],
      "source": [
        "config = AutoConfig.from_pretrained(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54HcwFI0sLGu"
      },
      "outputs": [],
      "source": [
        "\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "QqVDRQb3iv2k"
      },
      "outputs": [],
      "source": [
        "config_dict = config.to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vIkMTar2lZJh",
        "outputId": "2641b62e-deaf-417d-f5b6-5e53da798691"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['return_dict', 'output_hidden_states', 'output_attentions', 'torchscript', 'torch_dtype', 'use_bfloat16', 'tf_legacy_loss', 'pruned_heads', 'tie_word_embeddings', 'chunk_size_feed_forward', 'is_encoder_decoder', 'is_decoder', 'cross_attention_hidden_size', 'add_cross_attention', 'tie_encoder_decoder', 'max_length', 'min_length', 'do_sample', 'early_stopping', 'num_beams', 'num_beam_groups', 'diversity_penalty', 'temperature', 'top_k', 'top_p', 'typical_p', 'repetition_penalty', 'length_penalty', 'no_repeat_ngram_size', 'encoder_no_repeat_ngram_size', 'bad_words_ids', 'num_return_sequences', 'output_scores', 'return_dict_in_generate', 'forced_bos_token_id', 'forced_eos_token_id', 'remove_invalid_values', 'exponential_decay_length_penalty', 'suppress_tokens', 'begin_suppress_tokens', 'architectures', 'finetuning_task', 'id2label', 'label2id', 'tokenizer_class', 'prefix', 'bos_token_id', 'pad_token_id', 'eos_token_id', 'sep_token_id', 'decoder_start_token_id', 'task_specific_params', 'problem_type', '_name_or_path', '_commit_hash', '_attn_implementation_internal', 'transformers_version', 'auto_map', 'model_type', 'vision_config', 'llm_config', 'use_backbone_lora', 'use_llm_lora', 'select_layer', 'force_image_size', 'downsample_ratio', 'template', 'dynamic_image_size', 'use_thumbnail', 'ps_version', 'min_dynamic_patch', 'max_dynamic_patch'])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "QYa6WispltlO"
      },
      "outputs": [],
      "source": [
        "config_dict[\"vision_config\"][\"use_flash_attn\"] = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2DYulCBrQEb"
      },
      "outputs": [],
      "source": [
        "config_dict[\"llm_config\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1wuz-3xj1p4"
      },
      "outputs": [],
      "source": [
        "# eager\n",
        "config_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457,
          "referenced_widgets": [
            "a842ba9162324c80a7f787e6d18b96b1",
            "e7e1226985ac4af3a1c4277ebcd4687e",
            "96d68a8fab534c559142fd0b8db584c1",
            "b3a407cfff4d4597a58da63d48a7ef7d",
            "ffebf70fa96a4d0fa09703cf39849156",
            "be3f839fb0e54d0187480e17311eb042",
            "e8f5c3ebb1774f4a8a3046412759a48c",
            "f329904d58f248d0a479b6fff213a538",
            "347efdd92a624e25aced8e399185f205",
            "98ee61d724374e4082f41d5fce97c57f",
            "4415f08c6897469b9e37534d62c2ab49",
            "a99fa382c5374229a8384922e482953e",
            "10cc54e0d6864eb8b24a7ef16d322878",
            "fe072af8def640ca90b865490076d737",
            "4aadee85d88d46968db0f9754835f664",
            "a1e04933fa8641e3b9d8588699889c1f",
            "2bc89f6f213c46d8bfadd97a0592ab91",
            "d82008350a004b7481700f27ef77a2e2",
            "920591dea48a4310b33df830ed433952",
            "653b7681a2e749ff81c97630280dfab2",
            "d6c417925e174167b5c47d1b64084491",
            "63da8c9625e14dd1b2c145b65f8ba29b",
            "0f0d5b7cd6ce4c398cee2eb18a7a3c60",
            "b48aeecb17f94e6799e2caab93e932ee",
            "ad1392eeb5464a9baf534a5ebd3421cb",
            "cfaa2881a5424f24bb880ee8a63fab45",
            "b846dee22d6f41aa9a3eff0b38c2fc18",
            "edc088f8ae57477897709af0b86ecbf7",
            "9dc27a61bc524448af04953aebc7db1c",
            "b868f7256443483d868d17078bea0edd",
            "52fec7f355d940ceb43b5a6fe37dcba0",
            "69641b0a3332434aaf927a64e0386002",
            "a2e1acb839da44cba1d8424267721d95",
            "11ad8ad9672e412298d4e2fe0a3a8f23",
            "6fc8cd9ca8ba42deae758a9e75d3ef3d",
            "8e0f0ca46caf448ea2b196b8d0901015",
            "d477120153ac492b8b97503eca3c2efb",
            "4d53491d27fa484094b0664656cbd232",
            "ac5ea723d913445dae588b9ff3d74b83",
            "4a64418c94c04c31a6d04eafa61e19c5",
            "a335200ae95c44b7b6df8497fdcec388",
            "29b273e8b64e47e4a07e565af42ad7b9",
            "efda75efc3254d2eaebafde2e3754fa3",
            "5f2c2f83faa349118997e370ac8ac5dc",
            "088bd428892a461b9f28a5a772cd13e4",
            "2aad238314fb4c34a0ee67b4b9e5855e",
            "34110ef453984199b7a7332656472817",
            "c51b3034567443418f7964e9c02377dc",
            "6ec3e4f05b7242dd8a22492a3454e0d3",
            "8869773c108649d9a8d53b808ffa2deb",
            "2b33f083efb84075b3ef5f68fcf4369c",
            "3e66a757771b4632a8847b051ab51e00",
            "ce1ac1b6b9d447fc8c34b65f994edc10",
            "da5bea4369414135a5c8060f86e8b092",
            "227d66e61dd24a7eaaeb146f4111f6c9"
          ]
        },
        "id": "LIlIB_CItEL5",
        "outputId": "36063774-a72f-4c12-c021-8273d0cf8904"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a842ba9162324c80a7f787e6d18b96b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modeling_internvl_chat.py:   0%|          | 0.00/15.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a99fa382c5374229a8384922e482953e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modeling_intern_vit.py:   0%|          | 0.00/18.1k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/OpenGVLab/InternVL2_5-1B:\n",
            "- modeling_intern_vit.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f0d5b7cd6ce4c398cee2eb18a7a3c60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "conversation.py:   0%|          | 0.00/15.3k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/OpenGVLab/InternVL2_5-1B:\n",
            "- conversation.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "A new version of the following files was downloaded from https://huggingface.co/OpenGVLab/InternVL2_5-1B:\n",
            "- modeling_internvl_chat.py\n",
            "- modeling_intern_vit.py\n",
            "- conversation.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11ad8ad9672e412298d4e2fe0a3a8f23",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.88G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "088bd428892a461b9f28a5a772cd13e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/129 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = AutoModel.from_pretrained(\n",
        "    path,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    use_flash_attn=False,\n",
        "    trust_remote_code=True).eval().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jMzKYVVEWPij",
        "outputId": "46e1cc46-c277-4aab-ab2b-509983fea370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.37.2\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "azYiWYyodMWf",
        "outputId": "fe7908e2-90d9-4696-937b-77d5de135159"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Replacement done successfully!\n"
          ]
        }
      ],
      "source": [
        "file_path = \"/content/InternVL/internvl_chat/shell/internvl2.5/2nd_finetune/internvl2_5_1b_dynamic_res_2nd_finetune_lora.sh\"\n",
        "\n",
        "# Define the strings to replace\n",
        "old_string = \"./shell/data/internvl_1_2_finetune_custom.json\"\n",
        "new_string = \"/content/InternVL/internvl_chat/shell/data/train_metadata.jsonl\"\n",
        "\n",
        "# Read the file\n",
        "with open(file_path, \"r\") as file:\n",
        "    file_contents = file.read()\n",
        "\n",
        "# Replace the string\n",
        "file_contents = file_contents.replace(old_string, new_string)\n",
        "\n",
        "# Write back to the same file\n",
        "with open(file_path, \"w\") as file:\n",
        "    file.write(file_contents)\n",
        "\n",
        "print(\"Replacement done successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "etR47f9DMa1N"
      },
      "outputs": [],
      "source": [
        "os.chdir('/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "AEAy-VuwM1KY"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"/root/.cache/huggingface/hub/models--OpenGVLab--InternVL2_5-1B/snapshots/f27984381d99c1f2da11989d3216ca7b5bb51721/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dft8CnxFM8Mb",
        "outputId": "90c98f1c-8c37-4886-ec60-ca8be2dfdb2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".\t\t\t     configuration_internvl_chat.py  modeling_internvl_chat.py\n",
            "..\t\t\t     conversation.py\t\t     model.safetensors\n",
            "added_tokens.json\t     generation_config.json\t     special_tokens_map.json\n",
            "config.json\t\t     merges.txt\t\t\t     tokenizer_config.json\n",
            "configuration_intern_vit.py  modeling_intern_vit.py\t     vocab.json\n"
          ]
        }
      ],
      "source": [
        "!ls -a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "XvjEf_oWNoMU"
      },
      "outputs": [],
      "source": [
        "with open(\"config.json\", \"r\") as file:\n",
        "    config_data = json.load(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "T_NdUXNRNrYM"
      },
      "outputs": [],
      "source": [
        "config_data[\"llm_config\"][\"_attn_implementation\"] = \"eager\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSSdMwyROwMO",
        "outputId": "a1e77af4-6f1e-4a80-fe06-b84c1ac31975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/InternVL/internvl_chat\n"
          ]
        }
      ],
      "source": [
        "os.chdir('/content/InternVL/internvl_chat')\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6SP3RIIduOX",
        "outputId": "b4934cd6-3754-4bf0-bc11-88e28d097c30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+ GPUS=1\n",
            "+ BATCH_SIZE=16\n",
            "+ PER_DEVICE_BATCH_SIZE=1\n",
            "+ GRADIENT_ACC=16\n",
            "+ pwd\n",
            "+ export PYTHONPATH=/env/python:/content/InternVL/internvl_chat\n",
            "+ export MASTER_PORT=34229\n",
            "+ export TF_CPP_MIN_LOG_LEVEL=3\n",
            "+ export LAUNCHER=pytorch\n",
            "+ OUTPUT_DIR=work_dirs/internvl_chat_v2_5/internvl2_5_1b_dynamic_res_2nd_finetune_lora\n",
            "+ [ ! -d work_dirs/internvl_chat_v2_5/internvl2_5_1b_dynamic_res_2nd_finetune_lora ]\n",
            "+ tee -a work_dirs/internvl_chat_v2_5/internvl2_5_1b_dynamic_res_2nd_finetune_lora/training_log.txt\n",
            "+ torchrun --nnodes=1 --node_rank=0 --master_addr=127.0.0.1 --nproc_per_node=1 --master_port=34229 internvl/train/internvl_chat_finetune.py --model_name_or_path OpenGVLab/InternVL2_5-1B --conv_style internvl2_5 --use_fast_tokenizer False --output_dir work_dirs/internvl_chat_v2_5/internvl2_5_1b_dynamic_res_2nd_finetune_lora --meta_path /content/InternVL/internvl_chat/shell/data/train_metadata.jsonl --overwrite_output_dir True --force_image_size 448 --max_dynamic_patch 6 --down_sample_ratio 0.5 --drop_path_rate 0.0 --freeze_llm True --freeze_mlp True --freeze_backbone True --use_llm_lora 16 --vision_select_layer -1 --dataloader_num_workers 4 --bf16 True --num_train_epochs 1 --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --evaluation_strategy no --save_strategy steps --save_steps 200 --save_total_limit 1 --learning_rate 4e-5 --weight_decay 0.01 --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --max_seq_length 8192 --do_train True --grad_checkpoint True --group_by_length True --dynamic_image_size True --use_thumbnail True --ps_version v2 --deepspeed zero_stage1_config.json --report_to tensorboard\n",
            "[2025-02-21 15:58:45,181] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740153530.347317   11210 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740153530.353577   11210 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
            "petrel_client is not installed. Using PIL to load images.\n",
            "[2025-02-21 15:58:52,771] [INFO] [comm.py:658:init_distributed] cdb=None\n",
            "[2025-02-21 15:58:52,771] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "02/21/2025 15:58:52 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False\n",
            "02/21/2025 15:58:52 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=True,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=4,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=zero_stage1_config.json,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=16,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=True,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=4e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=work_dirs/internvl_chat_v2_5/internvl2_5_1b_dynamic_res_2nd_finetune_lora/runs/Feb21_15-58-52_a33d935af6d7,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=1.0,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.COSINE,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=1.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "output_dir=work_dirs/internvl_chat_v2_5/internvl2_5_1b_dynamic_res_2nd_finetune_lora,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=1,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=work_dirs/internvl_chat_v2_5/internvl2_5_1b_dynamic_res_2nd_finetune_lora,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=200,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=1,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=False,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.03,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.01,\n",
            ")\n",
            "02/21/2025 15:58:52 - INFO - __main__ - Loading Tokenizer: OpenGVLab/InternVL2_5-1B\n",
            "[INFO|tokenization_utils_base.py:2027] 2025-02-21 15:58:53,096 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--OpenGVLab--InternVL2_5-1B/snapshots/f27984381d99c1f2da11989d3216ca7b5bb51721/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2027] 2025-02-21 15:58:53,096 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--OpenGVLab--InternVL2_5-1B/snapshots/f27984381d99c1f2da11989d3216ca7b5bb51721/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2027] 2025-02-21 15:58:53,096 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--OpenGVLab--InternVL2_5-1B/snapshots/f27984381d99c1f2da11989d3216ca7b5bb51721/added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:2027] 2025-02-21 15:58:53,096 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--OpenGVLab--InternVL2_5-1B/snapshots/f27984381d99c1f2da11989d3216ca7b5bb51721/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2027] 2025-02-21 15:58:53,096 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--OpenGVLab--InternVL2_5-1B/snapshots/f27984381d99c1f2da11989d3216ca7b5bb51721/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2027] 2025-02-21 15:58:53,096 >> loading file tokenizer.json from cache at None\n",
            "[WARNING|logging.py:314] 2025-02-21 15:58:53,382 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "02/21/2025 15:58:53 - INFO - __main__ - Loading InternVLChatModel...\n",
            "[INFO|configuration_utils.py:729] 2025-02-21 15:58:53,497 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--OpenGVLab--InternVL2_5-1B/snapshots/f27984381d99c1f2da11989d3216ca7b5bb51721/config.json\n",
            "[INFO|configuration_utils.py:792] 2025-02-21 15:58:53,498 >> Model config InternVLChatConfig {\n",
            "  \"_commit_hash\": \"f27984381d99c1f2da11989d3216ca7b5bb51721\",\n",
            "  \"architectures\": [\n",
            "    \"InternVLChatModel\"\n",
            "  ],\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"OpenGVLab/InternVL2_5-1B--configuration_internvl_chat.InternVLChatConfig\",\n",
            "    \"AutoModel\": \"OpenGVLab/InternVL2_5-1B--modeling_internvl_chat.InternVLChatModel\",\n",
            "    \"AutoModelForCausalLM\": \"OpenGVLab/InternVL2_5-1B--modeling_internvl_chat.InternVLChatModel\"\n",
            "  },\n",
            "  \"downsample_ratio\": 0.5,\n",
            "  \"dynamic_image_size\": true,\n",
            "  \"force_image_size\": 448,\n",
            "  \"hidden_size\": 896,\n",
            "  \"llm_config\": {\n",
            "    \"_name_or_path\": \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
            "    \"add_cross_attention\": false,\n",
            "    \"architectures\": [\n",
            "      \"Qwen2ForCausalLM\"\n",
            "    ],\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"begin_suppress_tokens\": null,\n",
            "    \"bos_token_id\": 151643,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": 151645,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"hidden_act\": \"silu\",\n",
            "    \"hidden_size\": 896,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 4864,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 32768,\n",
            "    \"max_window_layers\": 21,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"qwen2\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"num_attention_heads\": 14,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 24,\n",
            "    \"num_key_value_heads\": 2,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": null,\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"rms_norm_eps\": 1e-06,\n",
            "    \"rope_theta\": 1000000.0,\n",
            "    \"sep_token_id\": null,\n",
            "    \"sliding_window\": 32768,\n",
            "    \"suppress_tokens\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tf_legacy_loss\": false,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": false,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": \"bfloat16\",\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.37.2\",\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": true,\n",
            "    \"use_cache\": true,\n",
            "    \"use_sliding_window\": false,\n",
            "    \"vocab_size\": 151674\n",
            "  },\n",
            "  \"max_dynamic_patch\": 12,\n",
            "  \"min_dynamic_patch\": 1,\n",
            "  \"model_type\": \"internvl_chat\",\n",
            "  \"pad2square\": false,\n",
            "  \"ps_version\": \"v2\",\n",
            "  \"select_layer\": -1,\n",
            "  \"template\": \"internvl2_5\",\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": null,\n",
            "  \"use_backbone_lora\": 0,\n",
            "  \"use_llm_lora\": 0,\n",
            "  \"use_thumbnail\": true,\n",
            "  \"vision_config\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"add_cross_attention\": false,\n",
            "    \"architectures\": [\n",
            "      \"InternVisionModel\"\n",
            "    ],\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"begin_suppress_tokens\": null,\n",
            "    \"bos_token_id\": null,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"drop_path_rate\": 0.0,\n",
            "    \"dropout\": 0.0,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": null,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_size\": 1024,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"image_size\": 448,\n",
            "    \"initializer_factor\": 1.0,\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 4096,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-06,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"intern_vit_6b\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"norm_type\": \"layer_norm\",\n",
            "    \"num_attention_heads\": 16,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_channels\": 3,\n",
            "    \"num_hidden_layers\": 24,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": null,\n",
            "    \"patch_size\": 14,\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"qk_normalization\": false,\n",
            "    \"qkv_bias\": true,\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"suppress_tokens\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tf_legacy_loss\": false,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": \"bfloat16\",\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.37.2\",\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": true,\n",
            "    \"use_flash_attn\": true\n",
            "  }\n",
            "}\n",
            "\n",
            "02/21/2025 15:58:53 - INFO - __main__ - Using flash_attention_2 for LLaMA\n",
            "[INFO|modeling_utils.py:3476] 2025-02-21 15:58:53,500 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--OpenGVLab--InternVL2_5-1B/snapshots/f27984381d99c1f2da11989d3216ca7b5bb51721/model.safetensors\n",
            "[INFO|modeling_utils.py:1426] 2025-02-21 15:58:53,519 >> Instantiating InternVLChatModel model under default dtype torch.bfloat16.\n",
            "[INFO|configuration_utils.py:826] 2025-02-21 15:58:53,520 >> Generate config GenerationConfig {}\n",
            "\n",
            "[INFO|configuration_utils.py:826] 2025-02-21 15:58:53,576 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:4350] 2025-02-21 15:58:56,056 >> All model checkpoint weights were used when initializing InternVLChatModel.\n",
            "\n",
            "[INFO|modeling_utils.py:4358] 2025-02-21 15:58:56,056 >> All the weights of InternVLChatModel were initialized from the model checkpoint at OpenGVLab/InternVL2_5-1B.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use InternVLChatModel for predictions without further training.\n",
            "[INFO|configuration_utils.py:781] 2025-02-21 15:58:56,168 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--OpenGVLab--InternVL2_5-1B/snapshots/f27984381d99c1f2da11989d3216ca7b5bb51721/generation_config.json\n",
            "[INFO|configuration_utils.py:826] 2025-02-21 15:58:56,169 >> Generate config GenerationConfig {\n",
            "  \"eos_token_id\": [\n",
            "    151644,\n",
            "    151645,\n",
            "    151643\n",
            "  ]\n",
            "}\n",
            "\n",
            "02/21/2025 15:58:56 - INFO - __main__ - Finished\n",
            "02/21/2025 15:58:56 - INFO - __main__ - model.config.force_image_size: 448\n",
            "02/21/2025 15:58:56 - INFO - __main__ - data_args.force_image_size: 448\n",
            "02/21/2025 15:58:56 - INFO - __main__ - model.config.vision_config.image_size: 448\n",
            "02/21/2025 15:58:56 - INFO - __main__ - [Dataset] num_image_token: 256\n",
            "02/21/2025 15:58:56 - INFO - __main__ - [Dataset] dynamic_image_size: True\n",
            "02/21/2025 15:58:56 - INFO - __main__ - [Dataset] use_thumbnail: True\n",
            "02/21/2025 15:58:56 - INFO - __main__ - [Dataset] min_dynamic_patch: 1, max_dynamic_patch: 6\n",
            "02/21/2025 15:58:56 - INFO - __main__ - Formatting inputs...Skip in lazy mode\n",
            "02/21/2025 15:58:56 - INFO - __main__ - Add dataset: data with length: 100\n",
            "trainable params: 8,798,208 || all params: 638,496,128 || trainable%: 1.3779579255334184\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight\n",
            "02/21/2025 15:58:57 - INFO - __main__ - language_model.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight\n",
            "[INFO|trainer.py:571] 2025-02-21 15:58:57,196 >> Using auto half precision backend\n",
            "[2025-02-21 15:58:57,725] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.4, git-hash=unknown, git-branch=unknown\n",
            "[2025-02-21 15:58:57,726] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 1\n",
            "[2025-02-21 15:58:58,800] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "Using /root/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py311_cu124/fused_adam/build.ninja...\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 0.05335521697998047 seconds\n",
            "[2025-02-21 15:58:58,858] [INFO] [logging.py:128:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
            "[2025-02-21 15:58:58,859] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
            "[2025-02-21 15:58:58,888] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
            "[2025-02-21 15:58:58,888] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
            "[2025-02-21 15:58:58,888] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 1 optimizer\n",
            "[2025-02-21 15:58:58,889] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 1000000000\n",
            "[2025-02-21 15:58:58,889] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 1000000000\n",
            "[2025-02-21 15:58:58,889] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
            "[2025-02-21 15:58:58,889] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
            "[2025-02-21 15:58:59,291] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states\n",
            "[2025-02-21 15:58:59,291] [INFO] [utils.py:782:see_memory_usage] MA 1.99 GB         Max_MA 2.01 GB         CA 2.13 GB         Max_CA 2 GB \n",
            "[2025-02-21 15:58:59,292] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 5.43 GB, percent = 42.9%\n",
            "[2025-02-21 15:58:59,653] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states\n",
            "[2025-02-21 15:58:59,654] [INFO] [utils.py:782:see_memory_usage] MA 1.99 GB         Max_MA 2.03 GB         CA 2.16 GB         Max_CA 2 GB \n",
            "[2025-02-21 15:58:59,654] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 5.43 GB, percent = 42.9%\n",
            "[2025-02-21 15:58:59,654] [INFO] [stage_1_and_2.py:550:__init__] optimizer state initialized\n",
            "[2025-02-21 15:59:00,007] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer\n",
            "[2025-02-21 15:59:00,008] [INFO] [utils.py:782:see_memory_usage] MA 1.99 GB         Max_MA 1.99 GB         CA 2.16 GB         Max_CA 2 GB \n",
            "[2025-02-21 15:59:00,008] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 5.43 GB, percent = 42.9%\n",
            "[2025-02-21 15:59:00,014] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer\n",
            "[2025-02-21 15:59:00,015] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed using client callable to create LR scheduler\n",
            "[2025-02-21 15:59:00,015] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7aff197db090>\n",
            "[2025-02-21 15:59:00,015] [INFO] [logging.py:128:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[[0.9, 0.999]]\n",
            "[2025-02-21 15:59:00,020] [INFO] [config.py:1001:print] DeepSpeedEngine configuration:\n",
            "[2025-02-21 15:59:00,021] [INFO] [config.py:1005:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2025-02-21 15:59:00,021] [INFO] [config.py:1005:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}\n",
            "[2025-02-21 15:59:00,021] [INFO] [config.py:1005:print]   amp_enabled .................. False\n",
            "[2025-02-21 15:59:00,021] [INFO] [config.py:1005:print]   amp_params ................... False\n",
            "[2025-02-21 15:59:00,021] [INFO] [config.py:1005:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": \"autotuning_results\", \n",
            "    \"exps_dir\": \"autotuning_exps\", \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2025-02-21 15:59:00,021] [INFO] [config.py:1005:print]   bfloat16_enabled ............. True\n",
            "[2025-02-21 15:59:00,022] [INFO] [config.py:1005:print]   bfloat16_immediate_grad_update  False\n",
            "[2025-02-21 15:59:00,022] [INFO] [config.py:1005:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2025-02-21 15:59:00,022] [INFO] [config.py:1005:print]   checkpoint_tag_validation_enabled  True\n",
            "[2025-02-21 15:59:00,022] [INFO] [config.py:1005:print]   checkpoint_tag_validation_fail  False\n",
            "[2025-02-21 15:59:00,022] [INFO] [config.py:1005:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7aff197ee2d0>\n",
            "[2025-02-21 15:59:00,022] [INFO] [config.py:1005:print]   communication_data_type ...... None\n",
            "[2025-02-21 15:59:00,022] [INFO] [config.py:1005:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2025-02-21 15:59:00,022] [INFO] [config.py:1005:print]   curriculum_enabled_legacy .... False\n",
            "[2025-02-21 15:59:00,022] [INFO] [config.py:1005:print]   curriculum_params_legacy ..... False\n",
            "[2025-02-21 15:59:00,022] [INFO] [config.py:1005:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
            "[2025-02-21 15:59:00,022] [INFO] [config.py:1005:print]   data_efficiency_enabled ...... False\n",
            "[2025-02-21 15:59:00,022] [INFO] [config.py:1005:print]   dataloader_drop_last ......... False\n",
            "[2025-02-21 15:59:00,022] [INFO] [config.py:1005:print]   disable_allgather ............ False\n",
            "[2025-02-21 15:59:00,023] [INFO] [config.py:1005:print]   dump_state ................... False\n",
            "[2025-02-21 15:59:00,023] [INFO] [config.py:1005:print]   dynamic_loss_scale_args ...... None\n",
            "[2025-02-21 15:59:00,023] [INFO] [config.py:1005:print]   eigenvalue_enabled ........... False\n",
            "[2025-02-21 15:59:00,023] [INFO] [config.py:1005:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2025-02-21 15:59:00,023] [INFO] [config.py:1005:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2025-02-21 15:59:00,023] [INFO] [config.py:1005:print]   eigenvalue_layer_num ......... 0\n",
            "[2025-02-21 15:59:00,023] [INFO] [config.py:1005:print]   eigenvalue_max_iter .......... 100\n",
            "[2025-02-21 15:59:00,023] [INFO] [config.py:1005:print]   eigenvalue_stability ......... 1e-06\n",
            "[2025-02-21 15:59:00,023] [INFO] [config.py:1005:print]   eigenvalue_tol ............... 0.01\n",
            "[2025-02-21 15:59:00,023] [INFO] [config.py:1005:print]   eigenvalue_verbose ........... False\n",
            "[2025-02-21 15:59:00,023] [INFO] [config.py:1005:print]   elasticity_enabled ........... False\n",
            "[2025-02-21 15:59:00,023] [INFO] [config.py:1005:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"recompute_fwd_factor\": 0.0, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2025-02-21 15:59:00,024] [INFO] [config.py:1005:print]   fp16_auto_cast ............... None\n",
            "[2025-02-21 15:59:00,024] [INFO] [config.py:1005:print]   fp16_enabled ................. False\n",
            "[2025-02-21 15:59:00,024] [INFO] [config.py:1005:print]   fp16_master_weights_and_gradients  False\n",
            "[2025-02-21 15:59:00,024] [INFO] [config.py:1005:print]   global_rank .................. 0\n",
            "[2025-02-21 15:59:00,024] [INFO] [config.py:1005:print]   grad_accum_dtype ............. None\n",
            "[2025-02-21 15:59:00,024] [INFO] [config.py:1005:print]   gradient_accumulation_steps .. 16\n",
            "[2025-02-21 15:59:00,024] [INFO] [config.py:1005:print]   gradient_clipping ............ 1.0\n",
            "[2025-02-21 15:59:00,024] [INFO] [config.py:1005:print]   gradient_predivide_factor .... 1.0\n",
            "[2025-02-21 15:59:00,024] [INFO] [config.py:1005:print]   graph_harvesting ............. False\n",
            "[2025-02-21 15:59:00,024] [INFO] [config.py:1005:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
            "[2025-02-21 15:59:00,024] [INFO] [config.py:1005:print]   initial_dynamic_scale ........ 1\n",
            "[2025-02-21 15:59:00,024] [INFO] [config.py:1005:print]   load_universal_checkpoint .... False\n",
            "[2025-02-21 15:59:00,024] [INFO] [config.py:1005:print]   loss_scale ................... 1.0\n",
            "[2025-02-21 15:59:00,024] [INFO] [config.py:1005:print]   memory_breakdown ............. False\n",
            "[2025-02-21 15:59:00,025] [INFO] [config.py:1005:print]   mics_hierarchial_params_gather  False\n",
            "[2025-02-21 15:59:00,025] [INFO] [config.py:1005:print]   mics_shard_size .............. -1\n",
            "[2025-02-21 15:59:00,025] [INFO] [config.py:1005:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')\n",
            "[2025-02-21 15:59:00,025] [INFO] [config.py:1005:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2025-02-21 15:59:00,025] [INFO] [config.py:1005:print]   optimizer_legacy_fusion ...... False\n",
            "[2025-02-21 15:59:00,025] [INFO] [config.py:1005:print]   optimizer_name ............... adamw\n",
            "[2025-02-21 15:59:00,025] [INFO] [config.py:1005:print]   optimizer_params ............. {'lr': 4e-05, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.01}\n",
            "[2025-02-21 15:59:00,025] [INFO] [config.py:1005:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
            "[2025-02-21 15:59:00,025] [INFO] [config.py:1005:print]   pld_enabled .................. False\n",
            "[2025-02-21 15:59:00,025] [INFO] [config.py:1005:print]   pld_params ................... False\n",
            "[2025-02-21 15:59:00,025] [INFO] [config.py:1005:print]   prescale_gradients ........... False\n",
            "[2025-02-21 15:59:00,025] [INFO] [config.py:1005:print]   scheduler_name ............... None\n",
            "[2025-02-21 15:59:00,026] [INFO] [config.py:1005:print]   scheduler_params ............. None\n",
            "[2025-02-21 15:59:00,026] [INFO] [config.py:1005:print]   seq_parallel_communication_data_type  torch.float32\n",
            "[2025-02-21 15:59:00,026] [INFO] [config.py:1005:print]   sparse_attention ............. None\n",
            "[2025-02-21 15:59:00,026] [INFO] [config.py:1005:print]   sparse_gradients_enabled ..... False\n",
            "[2025-02-21 15:59:00,026] [INFO] [config.py:1005:print]   steps_per_print .............. inf\n",
            "[2025-02-21 15:59:00,026] [INFO] [config.py:1005:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False\n",
            "[2025-02-21 15:59:00,026] [INFO] [config.py:1005:print]   timers_config ................ enabled=True synchronized=True\n",
            "[2025-02-21 15:59:00,026] [INFO] [config.py:1005:print]   train_batch_size ............. 16\n",
            "[2025-02-21 15:59:00,026] [INFO] [config.py:1005:print]   train_micro_batch_size_per_gpu  1\n",
            "[2025-02-21 15:59:00,026] [INFO] [config.py:1005:print]   use_data_before_expert_parallel_  False\n",
            "[2025-02-21 15:59:00,026] [INFO] [config.py:1005:print]   use_node_local_storage ....... False\n",
            "[2025-02-21 15:59:00,026] [INFO] [config.py:1005:print]   wall_clock_breakdown ......... True\n",
            "[2025-02-21 15:59:00,026] [INFO] [config.py:1005:print]   weight_quantization_config ... None\n",
            "[2025-02-21 15:59:00,026] [INFO] [config.py:1005:print]   world_size ................... 1\n",
            "[2025-02-21 15:59:00,027] [INFO] [config.py:1005:print]   zero_allow_untested_optimizer  False\n",
            "[2025-02-21 15:59:00,027] [INFO] [config.py:1005:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=1000000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=1000000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False\n",
            "[2025-02-21 15:59:00,027] [INFO] [config.py:1005:print]   zero_enabled ................. True\n",
            "[2025-02-21 15:59:00,027] [INFO] [config.py:1005:print]   zero_force_ds_cpu_optimizer .. True\n",
            "[2025-02-21 15:59:00,027] [INFO] [config.py:1005:print]   zero_optimization_stage ...... 1\n",
            "[2025-02-21 15:59:00,027] [INFO] [config.py:991:print_user_config]   json = {\n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 1, \n",
            "        \"allgather_partitions\": true, \n",
            "        \"allgather_bucket_size\": 1.000000e+09, \n",
            "        \"overlap_comm\": true, \n",
            "        \"reduce_scatter\": true, \n",
            "        \"reduce_bucket_size\": 1.000000e+09, \n",
            "        \"contiguous_gradients\": true\n",
            "    }, \n",
            "    \"fp16\": {\n",
            "        \"enabled\": false, \n",
            "        \"auto_cast\": true, \n",
            "        \"loss_scale\": 0, \n",
            "        \"initial_scale_power\": 32, \n",
            "        \"loss_scale_window\": 1000, \n",
            "        \"hysteresis\": 2, \n",
            "        \"min_loss_scale\": 1\n",
            "    }, \n",
            "    \"bf16\": {\n",
            "        \"enabled\": true\n",
            "    }, \n",
            "    \"optimizer\": {\n",
            "        \"type\": \"AdamW\", \n",
            "        \"params\": {\n",
            "            \"lr\": 4e-05, \n",
            "            \"betas\": [0.9, 0.999], \n",
            "            \"eps\": 1e-08, \n",
            "            \"weight_decay\": 0.01\n",
            "        }\n",
            "    }, \n",
            "    \"gradient_accumulation_steps\": 16, \n",
            "    \"gradient_clipping\": 1.0, \n",
            "    \"steps_per_print\": inf, \n",
            "    \"train_batch_size\": 16, \n",
            "    \"train_micro_batch_size_per_gpu\": 1, \n",
            "    \"wall_clock_breakdown\": true\n",
            "}\n",
            "[INFO|trainer.py:1721] 2025-02-21 15:59:00,027 >> ***** Running training *****\n",
            "[INFO|trainer.py:1722] 2025-02-21 15:59:00,027 >>   Num examples = 100\n",
            "[INFO|trainer.py:1723] 2025-02-21 15:59:00,027 >>   Num Epochs = 1\n",
            "[INFO|trainer.py:1724] 2025-02-21 15:59:00,027 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:1727] 2025-02-21 15:59:00,028 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:1728] 2025-02-21 15:59:00,028 >>   Gradient Accumulation steps = 16\n",
            "[INFO|trainer.py:1729] 2025-02-21 15:59:00,028 >>   Total optimization steps = 6\n",
            "[INFO|trainer.py:1730] 2025-02-21 15:59:00,031 >>   Number of trainable parameters = 8,798,208\n",
            "  0%|          | 0/6 [00:00<?, ?it/s][2025-02-21 15:59:02,577] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740153547.073111   11342 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740153547.079620   11342 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "[2025-02-21 15:59:12,953] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740153557.378199   11422 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740153557.384515   11422 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "[2025-02-21 15:59:23,219] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740153567.963827   11502 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740153567.970943   11502 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "[2025-02-21 15:59:33,099] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740153579.027746   11584 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740153579.034483   11584 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
            "petrel_client is not installed. Using PIL to load images.\n",
            "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
            "petrel_client is not installed. Using PIL to load images.\n",
            "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
            "petrel_client is not installed. Using PIL to load images.\n",
            "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
            "petrel_client is not installed. Using PIL to load images.\n",
            "[rank0]: Traceback (most recent call last):\n",
            "[rank0]:   File \"/content/InternVL/internvl_chat/internvl/train/internvl_chat_finetune.py\", line 1072, in <module>\n",
            "[rank0]:     main()\n",
            "[rank0]:   File \"/content/InternVL/internvl_chat/internvl/train/internvl_chat_finetune.py\", line 1057, in main\n",
            "[rank0]:     train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
            "[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 1539, in train\n",
            "[rank0]:     return inner_training_loop(\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 1869, in _inner_training_loop\n",
            "[rank0]:     tr_loss_step = self.training_step(model, inputs)\n",
            "[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2772, in training_step\n",
            "[rank0]:     loss = self.compute_loss(model, inputs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2795, in compute_loss\n",
            "[rank0]:     outputs = model(**inputs)\n",
            "[rank0]:               ^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "[rank0]:     return self._call_impl(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "[rank0]:     return forward_call(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/deepspeed/utils/nvtx.py\", line 18, in wrapped_fn\n",
            "[rank0]:     ret_val = func(*args, **kwargs)\n",
            "[rank0]:               ^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/deepspeed/runtime/engine.py\", line 1987, in forward\n",
            "[rank0]:     loss = self.module(*inputs, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "[rank0]:     return self._call_impl(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "[rank0]:     return forward_call(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/InternVL/internvl_chat/internvl/model/internvl_chat/modeling_internvl_chat.py\", line 164, in forward\n",
            "[rank0]:     vit_embeds = self.extract_feature(pixel_values)\n",
            "[rank0]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/InternVL/internvl_chat/internvl/model/internvl_chat/modeling_internvl_chat.py\", line 274, in extract_feature\n",
            "[rank0]:     vit_embeds = self.vision_model(\n",
            "[rank0]:                  ^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "[rank0]:     return self._call_impl(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "[rank0]:     return forward_call(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/InternVL/internvl_chat/internvl/model/internvl_chat/modeling_intern_vit.py\", line 414, in forward\n",
            "[rank0]:     encoder_outputs = self.encoder(\n",
            "[rank0]:                       ^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "[rank0]:     return self._call_impl(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "[rank0]:     return forward_call(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/InternVL/internvl_chat/internvl/model/internvl_chat/modeling_intern_vit.py\", line 345, in forward\n",
            "[rank0]:     layer_outputs = torch.utils.checkpoint.checkpoint(\n",
            "[rank0]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/_compile.py\", line 32, in inner\n",
            "[rank0]:     return disable_fn(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\", line 632, in _fn\n",
            "[rank0]:     return fn(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py\", line 489, in checkpoint\n",
            "[rank0]:     return CheckpointFunction.apply(function, preserve, *args)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\", line 575, in apply\n",
            "[rank0]:     return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py\", line 264, in forward\n",
            "[rank0]:     outputs = run_function(*args)\n",
            "[rank0]:               ^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "[rank0]:     return self._call_impl(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "[rank0]:     return forward_call(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/InternVL/internvl_chat/internvl/model/internvl_chat/modeling_intern_vit.py\", line 291, in forward\n",
            "[rank0]:     hidden_states = hidden_states + self.drop_path1(self.attn(self.norm1(hidden_states).to(hidden_states.dtype)) * self.ls1)\n",
            "[rank0]:                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "[rank0]:     return self._call_impl(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "[rank0]:     return forward_call(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/InternVL/internvl_chat/internvl/model/internvl_chat/modeling_intern_vit.py\", line 247, in forward\n",
            "[rank0]:     x = self._naive_attn(hidden_states) if not self.use_flash_attn else self._flash_attn(hidden_states)\n",
            "[rank0]:                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/InternVL/internvl_chat/internvl/model/internvl_chat/modeling_intern_vit.py\", line 239, in _flash_attn\n",
            "[rank0]:     context, _ = self.inner_attn(\n",
            "[rank0]:                  ^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "[rank0]:     return self._call_impl(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "[rank0]:     return forward_call(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/content/InternVL/internvl_chat/internvl/model/internvl_chat/modeling_intern_vit.py\", line 72, in forward\n",
            "[rank0]:     output = flash_attn_varlen_qkvpacked_func(\n",
            "[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/flash_attn/flash_attn_interface.py\", line 1267, in flash_attn_varlen_qkvpacked_func\n",
            "[rank0]:     return FlashAttnVarlenQKVPackedFunc.apply(\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\", line 575, in apply\n",
            "[rank0]:     return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/flash_attn/flash_attn_interface.py\", line 553, in forward\n",
            "[rank0]:     out_padded, softmax_lse, S_dmask, rng_state = _wrapped_flash_attn_varlen_forward(\n",
            "[rank0]:                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/_ops.py\", line 1116, in __call__\n",
            "[rank0]:     return self._op(*args, **(kwargs or {}))\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/_library/autograd.py\", line 113, in autograd_impl\n",
            "[rank0]:     result = forward_no_grad(*args, Metadata(keyset, keyword_only_args))\n",
            "[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/_library/autograd.py\", line 40, in forward_no_grad\n",
            "[rank0]:     result = op.redispatch(keyset & _C._after_autograd_keyset, *args, **kwargs)\n",
            "[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/_ops.py\", line 721, in redispatch\n",
            "[rank0]:     return self._handle.redispatch_boxed(keyset, *args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/_library/custom_ops.py\", line 324, in backend_impl\n",
            "[rank0]:     result = self._backend_fns[device_type](*args, **kwargs)\n",
            "[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/_compile.py\", line 32, in inner\n",
            "[rank0]:     return disable_fn(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\", line 632, in _fn\n",
            "[rank0]:     return fn(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/_library/custom_ops.py\", line 367, in wrapped_fn\n",
            "[rank0]:     return fn(*args, **kwargs)\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/flash_attn/flash_attn_interface.py\", line 170, in _flash_attn_varlen_forward\n",
            "[rank0]:     out, softmax_lse, S_dmask, rng_state = flash_attn_gpu.varlen_fwd(\n",
            "[rank0]:                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]: RuntimeError: FlashAttention only supports Ampere GPUs or newer.\n",
            "  0%|          | 0/6 [00:50<?, ?it/s]\n",
            "[rank0]:[W221 15:59:50.953384675 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
            "E0221 15:59:51.817000 11198 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 11210) of binary: /usr/bin/python3\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/torchrun\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py\", line 919, in main\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py\", line 910, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\n",
            "    raise ChildFailedError(\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "============================================================\n",
            "internvl/train/internvl_chat_finetune.py FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "  <NO_OTHER_FAILURES>\n",
            "------------------------------------------------------------\n",
            "Root Cause (first observed failure):\n",
            "[0]:\n",
            "  time      : 2025-02-21_15:59:51\n",
            "  host      : a33d935af6d7\n",
            "  rank      : 0 (local_rank: 0)\n",
            "  exitcode  : 1 (pid: 11210)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "!GPUS=1 PER_DEVICE_BATCH_SIZE=1 sh /content/InternVL/internvl_chat/shell/internvl2.5/2nd_finetune/internvl2_5_1b_dynamic_res_2nd_finetune_lora.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9S9_HZ3oC5m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2bFRDBibv1V",
        "outputId": "cbd59a6a-e6cb-47b3-c342-54b12ba67f82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "absl-py==1.4.0\n",
            "accelerate==0.34.2\n",
            "aiohappyeyeballs==2.4.6\n",
            "aiohttp==3.11.12\n",
            "aiosignal==1.3.2\n",
            "alabaster==1.0.0\n",
            "albucore==0.0.23\n",
            "albumentations==2.0.4\n",
            "ale-py==0.10.1\n",
            "altair==5.5.0\n",
            "annotated-types==0.7.0\n",
            "anyio==3.7.1\n",
            "argon2-cffi==23.1.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "array_record==0.6.0\n",
            "arviz==0.20.0\n",
            "astropy==7.0.1\n",
            "astropy-iers-data==0.2025.2.10.0.33.26\n",
            "astunparse==1.6.3\n",
            "atpublic==4.1.0\n",
            "attrs==25.1.0\n",
            "audioread==3.0.1\n",
            "autograd==1.7.0\n",
            "babel==2.17.0\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.13.3\n",
            "betterproto==2.0.0b6\n",
            "bigframes==1.36.0\n",
            "bigquery-magics==0.5.0\n",
            "bitsandbytes==0.45.2\n",
            "bleach==6.2.0\n",
            "blinker==1.9.0\n",
            "blis==0.7.11\n",
            "blosc2==3.1.0\n",
            "bokeh==3.6.3\n",
            "Bottleneck==1.4.2\n",
            "bqplot==0.12.44\n",
            "branca==0.8.1\n",
            "CacheControl==0.14.2\n",
            "cachetools==5.5.1\n",
            "catalogue==2.0.10\n",
            "certifi==2025.1.31\n",
            "cffi==1.17.1\n",
            "chardet==5.2.0\n",
            "charset-normalizer==3.4.1\n",
            "chex==0.1.88\n",
            "clarabel==0.10.0\n",
            "click==8.1.8\n",
            "cloudpathlib==0.20.0\n",
            "cloudpickle==3.1.1\n",
            "cmake==3.31.4\n",
            "cmdstanpy==1.2.5\n",
            "colorcet==3.1.0\n",
            "colorlover==0.3.0\n",
            "colour==0.1.5\n",
            "community==1.0.0b1\n",
            "confection==0.1.5\n",
            "cons==0.4.6\n",
            "contourpy==1.3.1\n",
            "cramjam==2.9.1\n",
            "cryptography==43.0.3\n",
            "cuda-python==12.6.0\n",
            "cudf-cu12 @ https://pypi.nvidia.com/cudf-cu12/cudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda12x==13.3.0\n",
            "cvxopt==1.3.2\n",
            "cvxpy==1.6.0\n",
            "cycler==0.12.1\n",
            "cyipopt==1.5.0\n",
            "cymem==2.0.11\n",
            "Cython==3.0.12\n",
            "dask==2024.10.0\n",
            "datascience==0.17.6\n",
            "datasets==3.3.2\n",
            "db-dtypes==1.4.1\n",
            "dbus-python==1.2.18\n",
            "debugpy==1.8.0\n",
            "decorator==4.4.2\n",
            "decord==0.6.0\n",
            "deepspeed==0.16.4\n",
            "defusedxml==0.7.1\n",
            "Deprecated==1.2.18\n",
            "diffusers==0.32.2\n",
            "dill==0.3.8\n",
            "distro==1.9.0\n",
            "dlib==19.24.2\n",
            "dm-tree==0.1.9\n",
            "dnspython==2.7.0\n",
            "docker-pycreds==0.4.0\n",
            "docstring_parser==0.16\n",
            "docutils==0.21.2\n",
            "dopamine_rl==4.1.2\n",
            "duckdb==1.1.3\n",
            "earthengine-api==1.5.2\n",
            "easydict==1.13\n",
            "editdistance==0.8.1\n",
            "eerepr==0.1.0\n",
            "einops==0.6.1\n",
            "einops-exts==0.0.4\n",
            "email_validator==2.2.0\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\n",
            "entrypoints==0.4\n",
            "et_xmlfile==2.0.0\n",
            "etils==1.12.0\n",
            "etuples==0.3.9\n",
            "Farama-Notifications==0.0.4\n",
            "fastai==2.7.18\n",
            "fastcore==1.7.29\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.21.1\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.3\n",
            "filelock==3.17.0\n",
            "firebase-admin==6.6.0\n",
            "flash_attn==2.7.4.post1\n",
            "Flask==3.1.0\n",
            "flatbuffers==25.2.10\n",
            "flax==0.10.3\n",
            "folium==0.19.4\n",
            "fonttools==4.56.0\n",
            "frozendict==2.4.6\n",
            "frozenlist==1.5.0\n",
            "fsspec==2024.10.0\n",
            "future==1.0.0\n",
            "gast==0.6.0\n",
            "gcsfs==2024.10.0\n",
            "GDAL==3.6.4\n",
            "gdown==5.2.0\n",
            "geemap==0.35.1\n",
            "gensim==4.3.3\n",
            "geocoder==1.38.1\n",
            "geographiclib==2.0\n",
            "geopandas==1.0.1\n",
            "geopy==2.4.1\n",
            "gin-config==0.5.0\n",
            "gitdb==4.0.12\n",
            "GitPython==3.1.44\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-ai-generativelanguage==0.6.15\n",
            "google-api-core==2.19.2\n",
            "google-api-python-client==2.160.0\n",
            "google-auth==2.27.0\n",
            "google-auth-httplib2==0.2.0\n",
            "google-auth-oauthlib==1.2.1\n",
            "google-cloud-aiplatform==1.79.0\n",
            "google-cloud-bigquery==3.25.0\n",
            "google-cloud-bigquery-connection==1.17.0\n",
            "google-cloud-bigquery-storage==2.28.0\n",
            "google-cloud-bigtable==2.28.1\n",
            "google-cloud-core==2.4.1\n",
            "google-cloud-dataproc==5.17.0\n",
            "google-cloud-datastore==2.20.2\n",
            "google-cloud-firestore==2.20.0\n",
            "google-cloud-functions==1.19.0\n",
            "google-cloud-iam==2.18.0\n",
            "google-cloud-language==2.16.0\n",
            "google-cloud-pubsub==2.25.0\n",
            "google-cloud-resource-manager==1.14.0\n",
            "google-cloud-spanner==3.51.0\n",
            "google-cloud-storage==2.19.0\n",
            "google-cloud-translate==3.19.0\n",
            "google-colab @ file:///colabtools/dist/google_colab-1.0.0.tar.gz\n",
            "google-crc32c==1.6.0\n",
            "google-genai==0.8.0\n",
            "google-generativeai==0.8.4\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.7.2\n",
            "google-spark-connect==0.5.2\n",
            "googleapis-common-protos==1.67.0\n",
            "googledrivedownloader==1.1.0\n",
            "graphviz==0.20.3\n",
            "greenlet==3.1.1\n",
            "grpc-google-iam-v1==0.14.0\n",
            "grpc-interceptor==0.15.4\n",
            "grpcio==1.70.0\n",
            "grpcio-status==1.62.3\n",
            "grpclib==0.4.7\n",
            "gspread==6.1.4\n",
            "gspread-dataframe==4.0.0\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "gymnasium==1.0.0\n",
            "h11==0.14.0\n",
            "h2==4.2.0\n",
            "h5netcdf==1.5.0\n",
            "h5py==3.12.1\n",
            "highspy==1.9.0\n",
            "hjson==3.1.0\n",
            "holidays==0.66\n",
            "holoviews==1.20.0\n",
            "hpack==4.1.0\n",
            "html5lib==1.1\n",
            "httpcore==1.0.7\n",
            "httpimport==1.4.0\n",
            "httplib2==0.22.0\n",
            "httpx==0.28.1\n",
            "huggingface-hub==0.28.1\n",
            "humanize==4.11.0\n",
            "hyperframe==6.1.0\n",
            "hyperopt==0.2.7\n",
            "ibis-framework==9.2.0\n",
            "id==1.5.0\n",
            "idna==3.10\n",
            "imageio==2.37.0\n",
            "imageio-ffmpeg==0.6.0\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.13.0\n",
            "imgaug==0.4.0\n",
            "immutabledict==4.2.1\n",
            "importlib_metadata==8.6.1\n",
            "importlib_resources==6.5.2\n",
            "imutils==0.5.4\n",
            "in-toto-attestation==0.9.3\n",
            "inflect==7.5.0\n",
            "iniconfig==2.0.0\n",
            "intel-cmplr-lib-ur==2025.0.4\n",
            "intel-openmp==2025.0.4\n",
            "ipyevents==2.0.2\n",
            "ipyfilechooser==0.6.0\n",
            "ipykernel==6.17.1\n",
            "ipyleaflet==0.19.2\n",
            "ipyparallel==8.8.0\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.5.0\n",
            "ipytree==0.2.2\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==2.2.0\n",
            "jax==0.4.33\n",
            "jax-cuda12-pjrt==0.4.33\n",
            "jax-cuda12-plugin==0.4.33\n",
            "jaxlib==0.4.33\n",
            "jeepney==0.7.1\n",
            "jellyfish==1.1.0\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.5\n",
            "jiter==0.8.2\n",
            "joblib==1.4.2\n",
            "jsonpatch==1.33\n",
            "jsonpickle==4.0.1\n",
            "jsonpointer==3.0.0\n",
            "jsonschema==4.23.0\n",
            "jsonschema-specifications==2024.10.1\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-leaflet==0.19.2\n",
            "jupyter-server==1.24.0\n",
            "jupyter_core==5.7.2\n",
            "jupyterlab_pygments==0.3.0\n",
            "jupyterlab_widgets==3.0.13\n",
            "kaggle==1.6.17\n",
            "kagglehub==0.3.7\n",
            "keras==3.8.0\n",
            "keras-hub==0.18.1\n",
            "keras-nlp==0.18.1\n",
            "keyring==23.5.0\n",
            "kiwisolver==1.4.8\n",
            "langchain==0.3.18\n",
            "langchain-core==0.3.35\n",
            "langchain-text-splitters==0.3.6\n",
            "langcodes==3.5.0\n",
            "langsmith==0.3.8\n",
            "language_data==1.3.0\n",
            "launchpadlib==1.10.16\n",
            "lazr.restfulclient==0.14.4\n",
            "lazr.uri==1.0.6\n",
            "lazy_loader==0.4\n",
            "libclang==18.1.1\n",
            "libcudf-cu12 @ https://pypi.nvidia.com/libcudf-cu12/libcudf_cu12-24.12.0-py3-none-manylinux_2_28_x86_64.whl\n",
            "libkvikio-cu12==24.12.1\n",
            "librosa==0.10.2.post1\n",
            "lightgbm==4.5.0\n",
            "linkify-it-py==2.0.3\n",
            "llvmlite==0.44.0\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.6\n",
            "lxml==5.3.1\n",
            "marisa-trie==1.2.1\n",
            "Markdown==3.7\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==3.0.2\n",
            "matplotlib==3.10.0\n",
            "matplotlib-inline==0.1.7\n",
            "matplotlib-venn==1.1.1\n",
            "mdit-py-plugins==0.4.2\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.3\n",
            "missingno==0.5.2\n",
            "mistune==3.1.1\n",
            "mizani==0.13.1\n",
            "mkl==2025.0.1\n",
            "ml-dtypes==0.4.1\n",
            "mlxtend==0.23.4\n",
            "model-signing==0.2.0\n",
            "more-itertools==10.6.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.1.0\n",
            "multidict==6.1.0\n",
            "multipledispatch==1.0.0\n",
            "multiprocess==0.70.16\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.12\n",
            "music21==9.3.0\n",
            "namex==0.0.8\n",
            "narwhals==1.26.0\n",
            "natsort==8.4.0\n",
            "nbclassic==1.2.0\n",
            "nbclient==0.10.2\n",
            "nbconvert==7.16.6\n",
            "nbformat==5.10.4\n",
            "ndindex==1.9.2\n",
            "nest-asyncio==1.6.0\n",
            "networkx==3.4.2\n",
            "nibabel==5.3.2\n",
            "ninja==1.11.1.3\n",
            "nltk==3.9.1\n",
            "notebook==6.5.5\n",
            "notebook_shim==0.2.4\n",
            "numba==0.61.0\n",
            "numba-cuda==0.0.17.1\n",
            "numexpr==2.10.2\n",
            "numpy==1.26.4\n",
            "nvidia-cublas-cu12==12.4.5.8\n",
            "nvidia-cuda-cupti-cu12==12.4.127\n",
            "nvidia-cuda-nvcc-cu12==12.5.82\n",
            "nvidia-cuda-nvrtc-cu12==12.4.127\n",
            "nvidia-cuda-runtime-cu12==12.4.127\n",
            "nvidia-cudnn-cu12==9.1.0.70\n",
            "nvidia-cufft-cu12==11.2.1.3\n",
            "nvidia-curand-cu12==10.3.5.147\n",
            "nvidia-cusolver-cu12==11.6.1.9\n",
            "nvidia-cusparse-cu12==12.3.1.170\n",
            "nvidia-ml-py==12.570.86\n",
            "nvidia-nccl-cu12==2.21.5\n",
            "nvidia-nvcomp-cu12==4.1.0.6\n",
            "nvidia-nvjitlink-cu12==12.4.127\n",
            "nvidia-nvtx-cu12==12.4.127\n",
            "nvtx==0.2.10\n",
            "nx-cugraph-cu12 @ https://pypi.nvidia.com/nx-cugraph-cu12/nx_cugraph_cu12-24.12.0-py3-none-any.whl\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "openai==1.61.1\n",
            "opencv-contrib-python==4.11.0.86\n",
            "opencv-python==4.11.0.86\n",
            "opencv-python-headless==4.11.0.86\n",
            "openpyxl==3.1.5\n",
            "opentelemetry-api==1.16.0\n",
            "opentelemetry-sdk==1.16.0\n",
            "opentelemetry-semantic-conventions==0.37b0\n",
            "opt_einsum==3.4.0\n",
            "optax==0.2.4\n",
            "optree==0.14.0\n",
            "orbax-checkpoint==0.6.4\n",
            "orjson==3.10.15\n",
            "osqp==0.6.7.post3\n",
            "packaging==24.2\n",
            "pandas==2.2.2\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.26.1\n",
            "pandas-stubs==2.2.2.240909\n",
            "pandocfilters==1.5.1\n",
            "panel==1.6.0\n",
            "param==2.2.0\n",
            "parso==0.8.4\n",
            "parsy==2.1\n",
            "partd==1.4.2\n",
            "pathlib==1.0.1\n",
            "patsy==1.0.1\n",
            "peewee==3.17.9\n",
            "peft==0.10.0\n",
            "pexpect==4.9.0\n",
            "pickleshare==0.7.5\n",
            "pillow==11.1.0\n",
            "platformdirs==4.3.6\n",
            "plotly==5.24.1\n",
            "plotnine==0.14.5\n",
            "pluggy==1.5.0\n",
            "ply==3.11\n",
            "polars==1.9.0\n",
            "pooch==1.8.2\n",
            "portpicker==1.5.2\n",
            "preshed==3.0.9\n",
            "prettytable==3.14.0\n",
            "proglog==0.1.10\n",
            "progressbar2==4.5.0\n",
            "prometheus_client==0.21.1\n",
            "promise==2.3\n",
            "prompt_toolkit==3.0.50\n",
            "propcache==0.2.1\n",
            "prophet==1.1.6\n",
            "proto-plus==1.26.0\n",
            "protobuf==4.25.6\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.10\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==17.0.0\n",
            "pyasn1==0.6.1\n",
            "pyasn1_modules==0.4.1\n",
            "pycocoevalcap==1.2\n",
            "pycocotools==2.0.8\n",
            "pycparser==2.22\n",
            "pydantic==2.10.6\n",
            "pydantic_core==2.27.2\n",
            "pydata-google-auth==1.9.1\n",
            "pydot==3.0.4\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "PyDrive2==1.21.3\n",
            "pyerfa==2.0.1.5\n",
            "pygame==2.6.1\n",
            "pygit2==1.17.0\n",
            "Pygments==2.18.0\n",
            "PyGObject==3.42.1\n",
            "PyJWT==2.10.1\n",
            "pylibcudf-cu12 @ https://pypi.nvidia.com/pylibcudf-cu12/pylibcudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "pylibcugraph-cu12==24.12.0\n",
            "pylibraft-cu12==24.12.0\n",
            "pymc==5.20.1\n",
            "pymystem3==0.2.0\n",
            "pynvjitlink-cu12==0.5.0\n",
            "pyogrio==0.10.0\n",
            "Pyomo==6.8.2\n",
            "PyOpenGL==3.1.9\n",
            "pyOpenSSL==24.2.1\n",
            "pyparsing==3.2.1\n",
            "pyperclip==1.9.0\n",
            "pyproj==3.7.0\n",
            "pyshp==2.3.1\n",
            "PySocks==1.7.1\n",
            "pyspark==3.5.4\n",
            "pytensor==2.27.1\n",
            "pytest==8.3.4\n",
            "python-apt==0.0.0\n",
            "python-box==7.3.2\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.16\n",
            "python-slugify==8.0.4\n",
            "python-snappy==0.7.3\n",
            "python-utils==3.9.1\n",
            "pytz==2025.1\n",
            "pyviz_comms==3.0.4\n",
            "PyYAML==6.0.2\n",
            "pyzmq==24.0.1\n",
            "qdldl==0.1.7.post5\n",
            "ratelim==0.1.6\n",
            "referencing==0.36.2\n",
            "regex==2024.11.6\n",
            "requests==2.32.3\n",
            "requests-oauthlib==2.0.0\n",
            "requests-toolbelt==1.0.0\n",
            "requirements-parser==0.9.0\n",
            "rfc3161-client==0.1.2\n",
            "rfc8785==0.1.4\n",
            "rich==13.9.4\n",
            "rmm-cu12==24.12.1\n",
            "rpds-py==0.22.3\n",
            "rpy2==3.4.2\n",
            "rsa==4.9\n",
            "safetensors==0.5.2\n",
            "scikit-image==0.25.1\n",
            "scikit-learn==1.6.1\n",
            "scipy==1.13.1\n",
            "scooby==0.10.0\n",
            "scs==3.2.7.post2\n",
            "seaborn==0.13.2\n",
            "SecretStorage==3.3.1\n",
            "securesystemslib==1.2.0\n",
            "Send2Trash==1.8.3\n",
            "sentence-transformers==3.4.1\n",
            "sentencepiece==0.1.99\n",
            "sentry-sdk==2.21.0\n",
            "setproctitle==1.3.4\n",
            "shap==0.46.0\n",
            "shapely==2.0.7\n",
            "shellingham==1.5.4\n",
            "shortuuid==1.0.13\n",
            "sigstore==3.6.1\n",
            "sigstore-protobuf-specs==0.3.2\n",
            "sigstore-rekor-types==0.0.18\n",
            "simple-parsing==0.1.7\n",
            "simsimd==6.2.1\n",
            "six==1.17.0\n",
            "sklearn-compat==0.1.3\n",
            "sklearn-pandas==2.2.0\n",
            "slicer==0.0.8\n",
            "smart-open==7.1.0\n",
            "smmap==5.0.2\n",
            "sniffio==1.3.1\n",
            "snowballstemmer==2.2.0\n",
            "soundfile==0.13.1\n",
            "soupsieve==2.6\n",
            "soxr==0.5.0.post1\n",
            "spacy==3.7.5\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.5\n",
            "spanner-graph-notebook==1.1.1\n",
            "Sphinx==8.1.3\n",
            "sphinxcontrib-applehelp==2.0.0\n",
            "sphinxcontrib-devhelp==2.0.0\n",
            "sphinxcontrib-htmlhelp==2.1.0\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==2.0.0\n",
            "sphinxcontrib-serializinghtml==2.0.0\n",
            "SQLAlchemy==2.0.38\n",
            "sqlglot==25.6.1\n",
            "sqlparse==0.5.3\n",
            "srsly==2.5.1\n",
            "stanio==0.5.1\n",
            "statsmodels==0.14.4\n",
            "stringzilla==3.11.3\n",
            "sympy==1.13.1\n",
            "tables==3.10.2\n",
            "tabulate==0.9.0\n",
            "tbb==2022.0.0\n",
            "tcmlib==1.2.0\n",
            "tenacity==9.0.0\n",
            "tensorboard==2.18.0\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorboardX==2.6.2.2\n",
            "tensorflow==2.18.0\n",
            "tensorflow-datasets==4.9.7\n",
            "tensorflow-hub==0.16.1\n",
            "tensorflow-io-gcs-filesystem==0.37.1\n",
            "tensorflow-metadata==1.16.1\n",
            "tensorflow-probability==0.25.0\n",
            "tensorflow-text==2.18.1\n",
            "tensorstore==0.1.71\n",
            "termcolor==2.5.0\n",
            "terminado==0.18.1\n",
            "text-unidecode==1.3\n",
            "textblob==0.19.0\n",
            "tf-slim==1.1.0\n",
            "tf_keras==2.18.0\n",
            "thinc==8.2.5\n",
            "threadpoolctl==3.5.0\n",
            "tifffile==2025.1.10\n",
            "timm==0.9.12\n",
            "tinycss2==1.4.0\n",
            "tokenizers==0.15.1\n",
            "toml==0.10.2\n",
            "toolz==0.12.1\n",
            "torch @ https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl\n",
            "torchaudio @ https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl\n",
            "torchsummary==1.5.1\n",
            "torchvision @ https://download.pytorch.org/whl/cu124/torchvision-0.20.1%2Bcu124-cp311-cp311-linux_x86_64.whl\n",
            "tornado==6.4.2\n",
            "tqdm==4.67.1\n",
            "traitlets==5.7.1\n",
            "traittypes==0.2.1\n",
            "transformers==4.37.2\n",
            "treescope==0.1.8\n",
            "triton==3.1.0\n",
            "tuf==5.1.0\n",
            "tweepy==4.15.0\n",
            "typeguard==4.4.1\n",
            "typer==0.15.1\n",
            "types-pytz==2025.1.0.20250204\n",
            "types-setuptools==75.8.0.20250210\n",
            "typing_extensions==4.12.2\n",
            "tzdata==2025.1\n",
            "tzlocal==5.3\n",
            "uc-micro-py==1.0.3\n",
            "umf==0.9.1\n",
            "uritemplate==4.1.1\n",
            "urllib3==2.3.0\n",
            "vega-datasets==0.9.0\n",
            "wadllib==1.3.6\n",
            "wandb==0.19.6\n",
            "wasabi==1.1.3\n",
            "wcwidth==0.2.13\n",
            "weasel==0.4.1\n",
            "webcolors==24.11.1\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.8.0\n",
            "websockets==14.2\n",
            "Werkzeug==3.1.3\n",
            "widgetsnbextension==3.6.10\n",
            "wordcloud==1.9.4\n",
            "wrapt==1.17.2\n",
            "xarray==2025.1.2\n",
            "xarray-einstats==0.8.0\n",
            "xgboost==2.1.4\n",
            "xlrd==2.0.1\n",
            "xxhash==3.5.0\n",
            "xyzservices==2025.1.0\n",
            "yacs==0.1.8\n",
            "yarl==1.18.3\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.52\n",
            "zipp==3.21.0\n",
            "zstandard==0.23.0\n"
          ]
        }
      ],
      "source": [
        "!pip freeze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "sBdGYl7hhOYf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "088bd428892a461b9f28a5a772cd13e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2aad238314fb4c34a0ee67b4b9e5855e",
              "IPY_MODEL_34110ef453984199b7a7332656472817",
              "IPY_MODEL_c51b3034567443418f7964e9c02377dc"
            ],
            "layout": "IPY_MODEL_6ec3e4f05b7242dd8a22492a3454e0d3"
          }
        },
        "0f0d5b7cd6ce4c398cee2eb18a7a3c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b48aeecb17f94e6799e2caab93e932ee",
              "IPY_MODEL_ad1392eeb5464a9baf534a5ebd3421cb",
              "IPY_MODEL_cfaa2881a5424f24bb880ee8a63fab45"
            ],
            "layout": "IPY_MODEL_b846dee22d6f41aa9a3eff0b38c2fc18"
          }
        },
        "10cc54e0d6864eb8b24a7ef16d322878": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bc89f6f213c46d8bfadd97a0592ab91",
            "placeholder": "​",
            "style": "IPY_MODEL_d82008350a004b7481700f27ef77a2e2",
            "value": "modeling_intern_vit.py: 100%"
          }
        },
        "11ad8ad9672e412298d4e2fe0a3a8f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fc8cd9ca8ba42deae758a9e75d3ef3d",
              "IPY_MODEL_8e0f0ca46caf448ea2b196b8d0901015",
              "IPY_MODEL_d477120153ac492b8b97503eca3c2efb"
            ],
            "layout": "IPY_MODEL_4d53491d27fa484094b0664656cbd232"
          }
        },
        "227d66e61dd24a7eaaeb146f4111f6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29b273e8b64e47e4a07e565af42ad7b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2aad238314fb4c34a0ee67b4b9e5855e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8869773c108649d9a8d53b808ffa2deb",
            "placeholder": "​",
            "style": "IPY_MODEL_2b33f083efb84075b3ef5f68fcf4369c",
            "value": "generation_config.json: 100%"
          }
        },
        "2b33f083efb84075b3ef5f68fcf4369c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bc89f6f213c46d8bfadd97a0592ab91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34110ef453984199b7a7332656472817": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e66a757771b4632a8847b051ab51e00",
            "max": 129,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce1ac1b6b9d447fc8c34b65f994edc10",
            "value": 129
          }
        },
        "347efdd92a624e25aced8e399185f205": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e66a757771b4632a8847b051ab51e00": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4415f08c6897469b9e37534d62c2ab49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a64418c94c04c31a6d04eafa61e19c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4aadee85d88d46968db0f9754835f664": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6c417925e174167b5c47d1b64084491",
            "placeholder": "​",
            "style": "IPY_MODEL_63da8c9625e14dd1b2c145b65f8ba29b",
            "value": " 18.1k/18.1k [00:00&lt;00:00, 412kB/s]"
          }
        },
        "4d53491d27fa484094b0664656cbd232": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52fec7f355d940ceb43b5a6fe37dcba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f2c2f83faa349118997e370ac8ac5dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63da8c9625e14dd1b2c145b65f8ba29b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "653b7681a2e749ff81c97630280dfab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69641b0a3332434aaf927a64e0386002": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ec3e4f05b7242dd8a22492a3454e0d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fc8cd9ca8ba42deae758a9e75d3ef3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac5ea723d913445dae588b9ff3d74b83",
            "placeholder": "​",
            "style": "IPY_MODEL_4a64418c94c04c31a6d04eafa61e19c5",
            "value": "model.safetensors: 100%"
          }
        },
        "8869773c108649d9a8d53b808ffa2deb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e0f0ca46caf448ea2b196b8d0901015": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a335200ae95c44b7b6df8497fdcec388",
            "max": 1876463472,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29b273e8b64e47e4a07e565af42ad7b9",
            "value": 1876463472
          }
        },
        "920591dea48a4310b33df830ed433952": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96d68a8fab534c559142fd0b8db584c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f329904d58f248d0a479b6fff213a538",
            "max": 15594,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_347efdd92a624e25aced8e399185f205",
            "value": 15594
          }
        },
        "98ee61d724374e4082f41d5fce97c57f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dc27a61bc524448af04953aebc7db1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1e04933fa8641e3b9d8588699889c1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2e1acb839da44cba1d8424267721d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a335200ae95c44b7b6df8497fdcec388": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a842ba9162324c80a7f787e6d18b96b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7e1226985ac4af3a1c4277ebcd4687e",
              "IPY_MODEL_96d68a8fab534c559142fd0b8db584c1",
              "IPY_MODEL_b3a407cfff4d4597a58da63d48a7ef7d"
            ],
            "layout": "IPY_MODEL_ffebf70fa96a4d0fa09703cf39849156"
          }
        },
        "a99fa382c5374229a8384922e482953e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10cc54e0d6864eb8b24a7ef16d322878",
              "IPY_MODEL_fe072af8def640ca90b865490076d737",
              "IPY_MODEL_4aadee85d88d46968db0f9754835f664"
            ],
            "layout": "IPY_MODEL_a1e04933fa8641e3b9d8588699889c1f"
          }
        },
        "ac5ea723d913445dae588b9ff3d74b83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad1392eeb5464a9baf534a5ebd3421cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b868f7256443483d868d17078bea0edd",
            "max": 15309,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52fec7f355d940ceb43b5a6fe37dcba0",
            "value": 15309
          }
        },
        "b3a407cfff4d4597a58da63d48a7ef7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98ee61d724374e4082f41d5fce97c57f",
            "placeholder": "​",
            "style": "IPY_MODEL_4415f08c6897469b9e37534d62c2ab49",
            "value": " 15.6k/15.6k [00:00&lt;00:00, 677kB/s]"
          }
        },
        "b48aeecb17f94e6799e2caab93e932ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edc088f8ae57477897709af0b86ecbf7",
            "placeholder": "​",
            "style": "IPY_MODEL_9dc27a61bc524448af04953aebc7db1c",
            "value": "conversation.py: 100%"
          }
        },
        "b846dee22d6f41aa9a3eff0b38c2fc18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b868f7256443483d868d17078bea0edd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be3f839fb0e54d0187480e17311eb042": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c51b3034567443418f7964e9c02377dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da5bea4369414135a5c8060f86e8b092",
            "placeholder": "​",
            "style": "IPY_MODEL_227d66e61dd24a7eaaeb146f4111f6c9",
            "value": " 129/129 [00:00&lt;00:00, 13.2kB/s]"
          }
        },
        "ce1ac1b6b9d447fc8c34b65f994edc10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfaa2881a5424f24bb880ee8a63fab45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69641b0a3332434aaf927a64e0386002",
            "placeholder": "​",
            "style": "IPY_MODEL_a2e1acb839da44cba1d8424267721d95",
            "value": " 15.3k/15.3k [00:00&lt;00:00, 1.52MB/s]"
          }
        },
        "d477120153ac492b8b97503eca3c2efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efda75efc3254d2eaebafde2e3754fa3",
            "placeholder": "​",
            "style": "IPY_MODEL_5f2c2f83faa349118997e370ac8ac5dc",
            "value": " 1.88G/1.88G [00:46&lt;00:00, 41.9MB/s]"
          }
        },
        "d6c417925e174167b5c47d1b64084491": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d82008350a004b7481700f27ef77a2e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da5bea4369414135a5c8060f86e8b092": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7e1226985ac4af3a1c4277ebcd4687e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be3f839fb0e54d0187480e17311eb042",
            "placeholder": "​",
            "style": "IPY_MODEL_e8f5c3ebb1774f4a8a3046412759a48c",
            "value": "modeling_internvl_chat.py: 100%"
          }
        },
        "e8f5c3ebb1774f4a8a3046412759a48c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "edc088f8ae57477897709af0b86ecbf7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efda75efc3254d2eaebafde2e3754fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f329904d58f248d0a479b6fff213a538": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe072af8def640ca90b865490076d737": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_920591dea48a4310b33df830ed433952",
            "max": 18063,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_653b7681a2e749ff81c97630280dfab2",
            "value": 18063
          }
        },
        "ffebf70fa96a4d0fa09703cf39849156": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
